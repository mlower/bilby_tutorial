{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c778901",
   "metadata": {},
   "source": [
    "# Solving your Bayesian dreams with `bilby` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d41b16",
   "metadata": {},
   "source": [
    "<img src=\"bilby.jpg\" alt=\"drawing\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11750b25",
   "metadata": {},
   "source": [
    "### What is `bilby`?\n",
    "\n",
    "A pure `Python`-based software package also known as the Bayesian Inference LiBrarY ([Ashton et al., 2019](https://ui.adsabs.harvard.edu/abs/2019ApJS..241...27A/abstract); [Romero-Shaw et al., 2020](https://ui.adsabs.harvard.edu/abs/2020MNRAS.499.3295R/abstract))\n",
    "\n",
    "Was originally developed solely as a user-friendly replacement for [`LALInference`](https://lscsoft.docs.ligo.org/lalsuite/lalinference/index.html), the parameter estimation package developed by LIGO for analysis of gravitational-wave events. It was adopted as the official parameter estimation code of the LIGO-Virgo-KAGRA collaboration during the 3rd observing run, and was used to analyse some of the most unusual gravitational-wave events detected to date, such as  [GW190425](https://ui.adsabs.harvard.edu/abs/2020ApJ...892L...3A/abstract), [GW190521](https://ui.adsabs.harvard.edu/abs/2020PhRvL.125j1102A/abstract) and [GW190814](https://ui.adsabs.harvard.edu/abs/2020ApJ...896L..44A/abstract).\n",
    "\n",
    "During early development it was soon realised the core functionality of `bilby` was general enough that it warrented compartmentalising the package so that the base functions (`bilby.core`) could be imported and utilised separately from the gravitational-wave specific components (`bilby.gw`). Most works outside of gravitational-wave astronomy that have utilised `bilby` tend use it as a user-friendly interface to several MCMC and nested sampling algorithms, such as the well-known affine-invariant MCMC sampler in Dan Foreman-Mackey's [`emcee`](https://github.com/dfm/emcee) package and the dynamic nested sampler built into [`dynesty`](https://github.com/joshspeagle/dynesty/).\n",
    "\n",
    "### Installing `bilby`\n",
    "\n",
    "First, you need to check whether you are using `Python3.7` or above. `Python2.7` will **not** work!\n",
    "\n",
    "The easiest (and recommended) way to install `bilby` is via `pip`:\n",
    "```\n",
    "pip install bilby\n",
    "```\n",
    "\n",
    "Alternatively, you can clone the GitLab repository: [https://git.ligo.org/lscsoft/bilby](https://git.ligo.org/lscsoft/bilby).\n",
    "\n",
    "\n",
    "### Useful Resources:\n",
    "\n",
    "Here's some links to useful papers and documents in case you're interested in how the underlying mathematic works\n",
    "* General introduction to Bayesian inference (slight focus on gravitational waves): [Thrane \\& Talbot (2019)](https://ui.adsabs.harvard.edu/abs/2019PASA...36...10T/abstract).\n",
    "* Mathematics behind nested sampling algorithms:[Skilling (2004)](https://aip.scitation.org/doi/abs/10.1063/1.1835238)\n",
    "* The MultiNest implemtation of nested sampling: [Feroz, Hobson \\& Bridges (2009)](https://ui.adsabs.harvard.edu/abs/2009MNRAS.398.1601F/abstract).\n",
    "\n",
    "If you ever run into issues, you can reach out to the `bilby` support desk: [contact+lscsoft-bilby-1846-issue-@support.ligo.org](contact+lscsoft-bilby-1846-issue-@support.ligo.org).\n",
    "\n",
    "Join the `bilby` Slack: [https://bilby-code.slack.com/](https://bilby-code.slack.com/).\n",
    "\n",
    "Or even ask `bilby`-tagged questions on [Stack Overflow](https://stackoverflow.com/questions/tagged/bilby)!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7de42b",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845a7cb5",
   "metadata": {},
   "source": [
    "# A quick primer: What is the goal of Bayesian parameter estimation?\n",
    "\n",
    "We want to know the probabilty that some model ($\\mu$) definied by some parameters ($\\theta$) matches some data ($d$).\n",
    "\n",
    "This can be done by evaluating Bayes' theorem:\n",
    "### $$ p(\\theta | d) = \\frac{\\mathcal{L}(d | \\theta) \\pi(\\theta)}{\\mathcal{Z}(d)} $$\n",
    "\n",
    "Here, $p(\\theta | d)$ is the posterior probability that the model parameters accurately describe the data, $\\mathcal{L}(d | \\theta)$ is the likelihood of the data given the chosen model parameters, $\\pi(\\theta)$ is our prior knowledge of what the model parameters should be, and $\\mathcal{Z}(d)$ is the Bayesian evidence (can ignore this for now...)\n",
    "\n",
    "Calculating the posterior probability distribution directly, especially if we have many model parameters, is difficult. We instead tend to generate *posterior samples* by using smart, stochastic sampling algorithms (e.g. MCMC and nested sampling) that explore all possible values of our model parameters and trend towards those with the highest probability of matching the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094a0159",
   "metadata": {},
   "source": [
    "# Getting started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26546d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257f00c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bilby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ce8845",
   "metadata": {},
   "outputs": [],
   "source": [
    "bilby?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd11dc51",
   "metadata": {},
   "source": [
    "## Model: Simple linear slope $\\rightarrow$ $ y = ax + c $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520d4af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def line(x, a, c):\n",
    "    \"\"\" A simple linear slope \"\"\"\n",
    "    return (a * x) + c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3516322c",
   "metadata": {},
   "source": [
    "## Making some fake data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad7b286",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "\n",
    "n = 10\n",
    "\n",
    "x = np.linspace(-10, 10, n)\n",
    "y = line(x, 0.5, 1)\n",
    "\n",
    "y_errs = 0.1 + 1.0 * np.random.rand(n)\n",
    "\n",
    "noise = np.random.uniform(-1.5, 1.5, n)\n",
    "\n",
    "data = y + noise\n",
    "\n",
    "plt.errorbar(x, data, yerr=y_errs, fmt=\"o\")\n",
    "plt.plot(x, y, \"--\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be97a6bd",
   "metadata": {},
   "source": [
    "# Using `bilby` to model the data\n",
    "\n",
    "## Example 1. Using the built-in Gaussian likelihood function\n",
    "\n",
    "In order to fit the data, we first need to define our likelihood function. \n",
    "\n",
    "The Gaussian likelihood is often used for this, where the residuals after subtracting our model would (ideally) look like Gaussian noise:\n",
    "\n",
    "### $$ \\mathcal{L}(d | \\theta) = \\prod_{i}^{N} \\frac{1}{\\sqrt{2 \\pi \\sigma^{2}}} \\exp \\Big[ -\\frac{(d_{i} - \\mu_{i}(\\theta))^{2}}{2\\sigma^{2}} \\Big] $$\n",
    "\n",
    "As implied by the name, the likelihood function tells us how *likely* it is that a given iteration of our model accurately matches the data.\n",
    "\n",
    "For this particular example, we're going to use the pre-built Gaussian likelihood in `bilby`, where the variance ($\\sigma$ in the above equation) is set to be our uncertainties on the data. This is called using `bilby.likelihood.GaussianLikelihood`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568ac8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bilby.likelihood.GaussianLikelihood?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d52bf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = bilby.likelihood.GaussianLikelihood(x=x,y=data, func=line, sigma=y_errs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c69a7f",
   "metadata": {},
   "source": [
    "### Setting the priors\n",
    "\n",
    "Next step in setting up our parameter estimation is setting up the priors. \n",
    "\n",
    "Priors are important, as they represent our pre-existing knowledge of what the model parameters should be. This includes things such as the allowed range of values we want to search over and whether some values are more probable than others. \n",
    "\n",
    "For the fake data we generated above, we're going to assume that we know nothing about the probability that one set of parameters matches the data better than another. Hence we assume *Uniform* priors between some upper and lower bounds\n",
    "\n",
    "### $$ \\pi(\\theta) = 1,\\,\\, {\\rm where} \\,\\, \\theta_{\\rm low} < \\theta < \\theta_{\\rm upp} $$\n",
    "\n",
    "The priors are defined as a `Python` dictionary (`priors = dict()`), where each dictionary key corresponds to one of our model parameters. E.g. `priors[\"a\"] = bilby.prior.Uniform(0, 1, \"a\")`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9969f387",
   "metadata": {},
   "outputs": [],
   "source": [
    "priors = dict()\n",
    "priors[\"a\"] = bilby.prior.Uniform(0, 1, \"a\")\n",
    "priors[\"c\"] = bilby.prior.Uniform(0, 4, \"c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e69ec8",
   "metadata": {},
   "source": [
    "### Running the parameter estimaiton\n",
    "\n",
    "Now that we've got our likelihood function and priors all set up, it's time to start sampling the posterior distributions!\n",
    "\n",
    "To do this, we're going to run `bilby` using the default sampler, `dynesty`, which uses a nested sampling algorithm to explore the parameter space. This is run via `bilby.run_sampler`.\n",
    "\n",
    "We will tell `dynesty` to explore the parameter space using 512 \"live points\". The more live points that are used, the more densly the parameter space will be explored, at the expense of the sampling taking much longer to converge to the most probable region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91e191e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bilby.run_sampler?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e824afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = bilby.run_sampler(likelihood=likelihood, priors=priors, sampler=\"dynesty\", nlive=512, \n",
    "                           label=\"line_test\", outdir=\"output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec6b2cf",
   "metadata": {},
   "source": [
    "### Looking at the results\n",
    "\n",
    "Once the sampling is complete, we can look at the resulting posterior probability distributions by running `result.plot_corner` to make a \"corner\" or \"triangle\" plot. \n",
    "These display the one- and two-dimensional posterior probability distributions in a way that makes it (relatively) easy to assess the level of covariance between individual model parameter.\n",
    "\n",
    "Parameters that are highly covariant will have 2-D posteriors that appear stretched or distorted (also known as having a \"degenerate\" solution), while uncorrelated parameters will look like round blobs.\n",
    "\n",
    "The orange lines and square correspond to the original \"injected\" or \"true\" values of `a` and `c` that were used to generate the fake data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021262ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the \"true\" values of a & c\n",
    "truths = dict(a=0.5, c=1.0)\n",
    "\n",
    "# Plot the 1- and 2-D posteriors alongside the true values\n",
    "result.plot_corner(truths=truths, dpi=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbbcd5a",
   "metadata": {},
   "source": [
    "### Posterior probability check\n",
    "\n",
    "So we've looked at the posterior distributions, and they (hopefully) look nice and well converged around the injected values of `a` and `c`. The next thing we can do is extract the median a-posteriori solution as well as a bunch of random draws from the posteriors and see how the resulting models compare against the data.\n",
    "\n",
    "We do this by first extracting the posterior samples for `a` and `c` using `result.posterior[\"a\"].values` and `result.posterior[\"b\"].values`. \n",
    "\n",
    "Note, that the posteriors samples in `result.posteriors` are saved to a `pandas` dataframe that can be queried using other methods as well.\n",
    "\n",
    "To plot the random draws from the posteriors, we just evaluate the model using random samples extracted from the `a` and `c`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a3f674",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_vals = result.posterior[\"a\"].values\n",
    "c_vals = result.posterior[\"c\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b1ebb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the median fit\n",
    "xfit = np.linspace(-12, 12, 32)\n",
    "med_model = line(xfit, np.median(a_vals), np.median(c_vals))\n",
    "\n",
    "# Plot the data\n",
    "plt.errorbar(x, data, yerr=y_errs, fmt=\"o\")\n",
    "\n",
    "# Plot 25 random draws from the posteriors\n",
    "for i in range(0, 25):\n",
    "    instance = line(xfit, a_vals[i], c_vals[i])\n",
    "    plt.plot(xfit, instance, lw=1, color=\"tab:orange\", alpha=0.3)\n",
    "\n",
    "# Plot the median fit & original injected slope:\n",
    "plt.plot(xfit, med_model, ls=\"-\", lw=2, color=\"k\", label=\"Median fit\")\n",
    "plt.plot(x, y, ls=\"--\", lw=2, color=\"tab:green\", label=\"Truth\")    \n",
    "plt.xlim(-11, 11)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ddf25d",
   "metadata": {},
   "source": [
    "### Getting the median values and uncertainties\n",
    "\n",
    "To extract the median a-posteriori values and 68% credible intervals (can be thought of as a \"1-sigma\" uncertainty), we can use `result.get_one_dimensional_median_and_error_bar(key)`, where `key=\"a\"` or `key=\"c\"`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522db082",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_result = result.get_one_dimensional_median_and_error_bar(\"a\")\n",
    "c_result = result.get_one_dimensional_median_and_error_bar(\"c\")\n",
    "\n",
    "print(\"Median and 68% C.I.\")\n",
    "print(\"a = {0} +{1}/-{2}\".format(round(a_result.median,2), round(a_result.plus,2), round(a_result.minus,2)))\n",
    "print(\"c = {0} +{1}/-{2}\".format(round(c_result.median,2), round(c_result.plus,2), round(c_result.minus,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037cdb8b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Example 2. Custom likelihood function\n",
    "\n",
    "Sometimes, we don't want to just use the basic, built-in likelihood functions that `bilby` comes with.\n",
    "In this example, we'll quickly go through how to use a custom made likelihood function that includes an extra \"error in quadrature\" (or EQUAD) term to account for possible underestimation of the uncertainties in our fake data.\n",
    "\n",
    "In this case, we'll again use a Gaussian likelihood function,\n",
    "\n",
    "### $$ \\mathcal{L}(d | \\theta) = \\prod_{i}^{N} \\frac{1}{\\sqrt{2 \\pi \\sigma_{i}^{2}}} \\exp \\Big[ -\\frac{(d_{i} - \\mu_{i}(\\theta))^{2}}{2\\sigma_{i}^{2}} \\Big], $$\n",
    "but this time the values of $\\sigma$ will be a little different.\n",
    "\n",
    "Instead of just passing the uncertainties on our y-values, we will instead add in this extra EQUAD parameter ($\\sigma_{Q}$) as \n",
    "\n",
    "### $$ \\sigma_{i}^{2} = \\sigma_{y,i}^{2} + \\sigma_{Q}^{2}. $$\n",
    "\n",
    "This will serve to inflate the uncertainties on our y-values by a small amount. \n",
    "\n",
    "Writing custom likelihood functions can be a little tricky at first, especially if you're unfamiliar with `Python` classes. So for this example, we're essentially re-writing the default Gaussian likelihood function in `bilby` to take this extra EQUAD parameter as well as our normal model and model parameter.\n",
    "\n",
    "Note, this likelihood function will require some additional modifications if you want to use it with a more general model, instead of just our current `line` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e84355",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomGaussianLikelihood(bilby.likelihood.Likelihood):\n",
    "    def __init__(self, x, y, y_err, func, parameters):\n",
    "        \"\"\"\n",
    "        Custom Gaussian Likelihood\n",
    "\n",
    "        A modified version of the Gaussian likelihood for fitting\n",
    "        straight lines. Also incorperates an EQUAD parameter.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : ndarray\n",
    "            Array of independent values.\n",
    "        y : ndarray\n",
    "            Array of dependent values.\n",
    "        y_err : ndarray \n",
    "            Formal errors on the dependent values.\n",
    "        func : function\n",
    "            Function containing the model to be fit to the data.\n",
    "        parameters : dict_like\n",
    "            Dictionary of parameter keys.\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__()\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.y_err = y_err\n",
    "        self.func = func\n",
    "        self.parameters = parameters\n",
    "        \n",
    "    def log_likelihood(self):\n",
    "        self.sigma = np.sqrt((self.y_err**2) + (self.parameters[\"sigma\"]**2))\n",
    "        \n",
    "        self.model = self.func(self.x, self.parameters[\"a\"], self.parameters[\"c\"])\n",
    "        self.residual = (self.y - self.model)**2\n",
    "\n",
    "        ln_like = np.sum(- (self.residual / (2 * self.sigma**2))\n",
    "            - np.log(2 * np.pi * self.sigma**2) / 2)\n",
    "\n",
    "        return ln_like"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426bb683",
   "metadata": {},
   "source": [
    "### Running `bilby` with the custom likelihood\n",
    "\n",
    "And now, we just initialise and then run `bilby` as before!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef506a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the parameters dictionary\n",
    "parameters = dict(a=None, c=None, sigma=None)\n",
    "\n",
    "# Initialise the likelihood function\n",
    "likelihood = CustomGaussianLikelihood(x=x, y=y, y_err=y_errs, func=line, parameters=parameters)\n",
    "\n",
    "# Set priors\n",
    "priors = dict()\n",
    "priors[\"a\"] = bilby.prior.Uniform(0, 1, \"a\")\n",
    "priors[\"c\"] = bilby.prior.Uniform(0, 4, \"c\")\n",
    "priors[\"sigma\"] = bilby.prior.Uniform(0, 1, \"sigma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89769e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = bilby.run_sampler(likelihood=likelihood, priors=priors, sampler=\"dynesty\", nlive=512, \n",
    "                           label=\"custom_priors\", outdir=\"output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebad3a7",
   "metadata": {},
   "source": [
    "### Inspecting the posterior distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9857e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "truths = dict(a=0.5, c=1.0, sigma=None)\n",
    "\n",
    "result.plot_corner(truths=truths, dpi=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb5aabb",
   "metadata": {},
   "source": [
    "### Posterior predictive check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c135460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the posteriors\n",
    "a_vals = result.posterior[\"a\"].values\n",
    "c_vals = result.posterior[\"c\"].values\n",
    "sigmas = result.posterior[\"sigma\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe945b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the median model\n",
    "xfit = np.linspace(-12, 12, 32)\n",
    "med_model = line(xfit, np.median(a_vals), np.median(c_vals))\n",
    "\n",
    "# Plot the data with errorbars inflated by the median EQUAD value \n",
    "plt.errorbar(x, data, yerr=np.sqrt(y_errs**2 + np.median(sigmas**2)), fmt=\"o\")\n",
    "\n",
    "# Plot 25 random draws from the posterior\n",
    "for i in range(0, 25):\n",
    "    instance = line(xfit, a_vals[i], c_vals[i])\n",
    "    plt.plot(xfit, instance, lw=1, color=\"tab:orange\", alpha=0.3)\n",
    "\n",
    "# Plot the median fit & original injected slope:\n",
    "plt.plot(xfit, med_model, ls=\"-\", lw=2, color=\"k\", label=\"Median fit\")\n",
    "plt.plot(x, y, ls=\"--\", lw=2, color=\"tab:green\", label=\"Truth\")    \n",
    "plt.xlim(-11, 11)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefad0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_result = result.get_one_dimensional_median_and_error_bar(\"a\")\n",
    "c_result = result.get_one_dimensional_median_and_error_bar(\"c\")\n",
    "sigma_result = result.get_one_dimensional_median_and_error_bar(\"sigma\")\n",
    "\n",
    "print(\"Median and 68% C.I.\")\n",
    "print(\"a = {0} +{1}/-{2}\".format(round(a_result.median,2), round(a_result.plus,2), round(a_result.minus,2)))\n",
    "print(\"c = {0} +{1}/-{2}\".format(round(c_result.median,2), round(c_result.plus,2), round(c_result.minus,2)))\n",
    "print(\"sigma = {0} +{1}/-{2}\".format(round(sigma_result.median,2), round(sigma_result.plus,2), \n",
    "                                     round(sigma_result.minus,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab157a2",
   "metadata": {},
   "source": [
    "### So how'd it do?\n",
    "\n",
    "The median recovered values exactly match the initial values that we injected! However, the 68% credible intervals for both `a` and `c` are a little larger. \n",
    "\n",
    "This larger uncertainty makes sense though, as we've added an extra level of uncertainty into the data by including the EQUAD parameter. Therefore a slightly wider range of possible models can adequetely fit within the inflated data uncertainties."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6291f420",
   "metadata": {},
   "source": [
    "---\n",
    "## Example 3. Model selection\n",
    "\n",
    "One of the most powerful applications of Bayesian inference is comparing whether two or more different models provide a better match to the data. \n",
    "This process, known as Bayesian model selection relies on that *Evidence* parameter, $\\mathcal{Z}(d)$ from before.\n",
    "\n",
    "In this case, we're going to re-fit our fake data from before using a quadratic function instead of a simple linear fit, and test whether it is the preferred model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d768360",
   "metadata": {},
   "source": [
    "### Simple quadratic model: $y = ax^{2} + bx +c$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20edf4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quadratic(x, a, b, c):\n",
    "    \"\"\" A simple quadratic function \"\"\"\n",
    "    return (a * x**2) + (b * x) + c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c18620",
   "metadata": {},
   "source": [
    "### Setting up the likelihood & priors\n",
    "\n",
    "As in Example 1, we're just going to use the pre-existing Gaussian likelihood that is built into `bilby`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b6e696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the likelihood function\n",
    "likelihood = bilby.likelihood.GaussianLikelihood(x=x,y=data, func=quadratic, sigma=y_errs)\n",
    "\n",
    "# Set-up the priors\n",
    "priors = dict()\n",
    "priors[\"a\"] = bilby.prior.Uniform(-2, 2, \"a\")\n",
    "priors[\"b\"] = bilby.prior.Uniform(-2, 2, \"b\")\n",
    "priors[\"c\"] = bilby.prior.Uniform(-2, 2, \"c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d67cabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_quad = bilby.run_sampler(likelihood=likelihood, priors=priors, sampler=\"dynesty\", nlive=512, \n",
    "                                label=\"quadratic_test\", outdir=\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c21ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the 1- & 2-D posteriors\n",
    "result_quad.plot_corner(dpi=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78c84bd",
   "metadata": {},
   "source": [
    "### Posterior predictive checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a59631",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_vals = result_quad.posterior[\"a\"].values\n",
    "b_vals = result_quad.posterior[\"b\"].values\n",
    "c_vals = result_quad.posterior[\"c\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035a87e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the median model\n",
    "xfit = np.linspace(-12, 12, 32)\n",
    "med_model = quadratic(xfit, np.median(a_vals), np.median(b_vals), np.median(c_vals))\n",
    "\n",
    "# Plot the data\n",
    "plt.errorbar(x, data, yerr=y_errs, fmt=\"o\")\n",
    "\n",
    "# Plot 25 random draws from the posterior\n",
    "for i in range(0, 25):\n",
    "    instance = quadratic(xfit, a_vals[i], b_vals[i], c_vals[i])\n",
    "    plt.plot(xfit, instance, lw=1, color=\"tab:orange\", alpha=0.3)\n",
    "\n",
    "    \n",
    "# Plot the median fit & original injected slope:\n",
    "plt.plot(xfit, med_model, ls=\"-\", lw=2, color=\"k\", label=\"Median fit\")\n",
    "plt.plot(x, y, ls=\"--\", lw=2, color=\"tab:green\", label=\"Truth\")    \n",
    "plt.xlim(-11, 11)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65949953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the 1-D median and 68% upper & lower confidence intervals\n",
    "a_result = result_quad.get_one_dimensional_median_and_error_bar(\"a\")\n",
    "b_result = result_quad.get_one_dimensional_median_and_error_bar(\"b\")\n",
    "c_result = result_quad.get_one_dimensional_median_and_error_bar(\"c\")\n",
    "\n",
    "print(\"Median and 68% C.I.\")\n",
    "print(\"a = {0} +{1}/-{2}\".format(round(a_result.median,2), round(a_result.plus,2), round(a_result.minus,2)))\n",
    "print(\"b = {0} +{1}/-{2}\".format(round(b_result.median,2), round(b_result.plus,2), round(b_result.minus,2)))\n",
    "print(\"c = {0} +{1}/-{2}\".format(round(c_result.median,2), round(c_result.plus,2), round(c_result.minus,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf0cd81",
   "metadata": {},
   "source": [
    "### Comparing the quadratic versus linear models\n",
    "\n",
    "Just by looking at the posteriors and posterior predictive plots, it's pretty clear that the full quadratic model isn't fitting the data as well as our previous linear fits. \n",
    "\n",
    "However, to quantitatively determine which model best describes the data, we must first read in the results from our old linear fit using `bilby.result.read_in_result` as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a314d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_line = bilby.result.read_in_result(\"./output/line_test_result.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a1efe1",
   "metadata": {},
   "source": [
    "### Computing the Bayes factor\n",
    "\n",
    "Now that we have both sets of results read in, we can use the Bayesian evidences that were computed by `dynesty` to determine which model best describes the data. \n",
    "\n",
    "As a quick aside, the Bayesian evidence is simply the integral of our likelihood function over all values of our model parameters (sometimes referred to as the \"fully marginalised\" likelihood)\n",
    "### $$ \\mathcal{Z}(d) = \\int d\\theta \\mathcal{L}(d | \\theta) \\pi(\\theta) $$\n",
    "Thankfully, `dynesty` provides the evidence as an output. So we don't have to try and compute this integral ourselves (which can be quite a painful process!).\n",
    "\n",
    "Once we have the evidences for our two models, we can then compute the \"Bayes factor\" by dividing the evidence for model 1 by the evidence for model 2 (this is why the Bayes factor is sometimes referred to as the \"ratio of evidences\").\n",
    "### $$ \\mathcal{B}_{1/2} = \\frac{\\mathcal{Z}_{1}}{\\mathcal{Z}_{2}} $$\n",
    "\n",
    "One thing to note for our case is that we have computed the likelihood function in natural log space (i.e as a \"log-likelihood\"). This is mainly to avoid numerical precision issues that can arise when dealing with either very large or very small numbers. \n",
    "As a result, we extract the \"log-evidences\" from our `result` objects using `result.log_evidence`, and compute a \"log Bayes factor\" by subtracting the log-evidence of model 2 from model 1 as\n",
    "### $$ \\ln \\mathcal{B}_{1/2} = \\ln \\mathcal{Z}_{1} - \\ln \\mathcal{Z}_{2} .$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3283dbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the log-evidences for the linear & quadratic fits\n",
    "lnZ_line = result_line.log_evidence\n",
    "lnZ_quad = result_quad.log_evidence\n",
    "\n",
    "# Compute log Bayes factor\n",
    "lnBF = lnZ_line - lnZ_quad\n",
    "\n",
    "print(\"log Bayes factor = {0}\".format(lnBF))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37815691",
   "metadata": {},
   "source": [
    "### Interpreting the Bayes factor\n",
    "\n",
    "Exactly what makes a \"good\" Bayes factor threshold, i.e the minimum Bayes factor needed to say one model is more strongly preferred over another, is somewhat of a personal opinion. \n",
    "\n",
    "An often used interpretation comes from [Kass & Raferty (1995)](). Here, $\\ln\\mathcal{B} > 5$ means one model is considered *very strongly* preferred over the other, $3 < \\ln\\mathcal{B} < 5$ indicates the model is *moderately* preferred over the other, $1 < \\ln\\mathcal{B} < 3$ is a *weak* preference of one over the other, and $0 < \\ln\\mathcal{B} < 1$ is a marginal preference of one model over the other.\n",
    "\n",
    "In the case of a marginal preference, then we often tend assume the simplest model provides an adequete represntation of the data and is therefore *preferred*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f201cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
